{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naïve Bayes \n",
    "is a simple but powerful classifier based on a probabilistic model\n",
    "derived from the Bayes' theorem. Basically it determines the probability that an\n",
    "instance belongs to a class based on each of the feature value probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most successful applications of Naïve Bayes has been within the field\n",
    "of Natural Language Processing (NLP). NLP is a field that has been much related\n",
    "to machine learning, since many of its problems can be formulated as a classification\n",
    "task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will use Naïve Bayes for text classification; we will have a set of\n",
    "text documents with their corresponding categories, and we will train a Naïve Bayes\n",
    "algorithm to learn to predict the categories of new unseen instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing our pylab environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the newsgroup Dataset, explore its structure and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['target_names', 'data', 'description', 'target', 'DESCR', 'filenames'])\n",
      "<class 'list'> <class 'numpy.ndarray'> <class 'list'>\n",
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n",
      "18846\n",
      "18846\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "news = fetch_20newsgroups(subset='all')\n",
    "print (news.keys())\n",
    "print (type(news.data), type(news.target), type(news.target_names))\n",
    "print (news.target_names)\n",
    "print (len(news.data))\n",
    "print (len(news.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: Mamatha Devineni Ratnam <mr47+@andrew.cmu.edu>\n",
      "Subject: Pens fans reactions\n",
      "Organization: Post Office, Carnegie Mellon, Pittsburgh, PA\n",
      "Lines: 12\n",
      "NNTP-Posting-Host: po4.andrew.cmu.edu\n",
      "\n",
      "\n",
      "\n",
      "I am sure some bashers of Pens fans are pretty confused about the lack\n",
      "of any kind of posts about the recent Pens massacre of the Devils. Actually,\n",
      "I am  bit puzzled too and a bit relieved. However, I am going to put an end\n",
      "to non-PIttsburghers' relief with a bit of praise for the Pens. Man, they\n",
      "are killing those Devils worse than I thought. Jagr just showed you why\n",
      "he is much better than his regular season stats. He is also a lot\n",
      "fo fun to watch in the playoffs. Bowman should let JAgr have a lot of\n",
      "fun in the next couple of games since the Pens are going to beat the pulp out of Jersey anyway. I was very disappointed not to see the Islanders lose the final\n",
      "regular season game.          PENS RULE!!!\n",
      "\n",
      "\n",
      "10 rec.sport.hockey\n"
     ]
    }
   ],
   "source": [
    "print (news.data[0])\n",
    "print (news.target[0], news.target_names[news.target[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to partition our data into training and\n",
    "testing set. The loaded data is already in a random order, so we only have to split the\n",
    "data into, for example, 75 percent for training and the rest 25 percent for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SPLIT_PERC = 0.75\n",
    "split_size = int(len(news.data)*SPLIT_PERC)\n",
    "X_train = news.data[:split_size]\n",
    "X_test = news.data[split_size:]\n",
    "y_train = news.target[:split_size]\n",
    "y_test = news.target[split_size:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will serve to perform and evaluate a cross validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score, KFold\n",
    "from scipy.stats import sem\n",
    "\n",
    "def evaluate_cross_validation(clf, X, y, K):\n",
    "    # create a k-fold croos validation iterator of k=5 folds\n",
    "    cv = KFold(len(y), K, shuffle=True, random_state=0)\n",
    "    # by default the score used is the one returned by score method of the estimator (accuracy)\n",
    "    scores = cross_val_score(clf, X, y, cv=cv)\n",
    "    print (scores)\n",
    "    print ((\"Mean score: {0:.3f} (+/-{1:.3f})\").format(\n",
    "        np.mean(scores), sem(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our machine learning algorithms can work only on numeric data.Currently we\n",
    "only have one feature, the text content of the message; we need some function that\n",
    "transforms a text into a meaningful set of numeric features.\n",
    "\n",
    "The sklearn.\n",
    "feature_extraction.text module has some useful utilities to build numeric\n",
    "feature vectors from text documents.\n",
    "\n",
    "You\n",
    "will find three different classes that can transform text into numeric features:\n",
    "CountVectorizer, HashingVectorizer, and TfidfVectorizer. The difference\n",
    "between them resides in the calculations they perform to obtain the numeric features.\n",
    "CountVectorizer basically creates a dictionary of words from the text corpus. Then,\n",
    "each instance is converted to a vector of numeric features where each element will be\n",
    "the count of the number of times a particular word appears in the document.\n",
    "\n",
    "HashingVectorizer, instead of constricting and maintaining the dictionary in\n",
    "memory, implements a hashing function that maps tokens into feature indexes, and\n",
    "then computes the count as in CountVectorizer.\n",
    "\n",
    "TfidfVectorizer works like the CountVectorizer, but with a more advanced\n",
    "calculation called Term Frequency Inverse Document Frequency (TF-IDF). This is a\n",
    "statistic for measuring the importance of a word in a document or corpus. Intuitively,\n",
    "it looks for words that are more frequent in the current document, compared with\n",
    "their frequency in the whole corpus of documents. You can see this as a way to\n",
    "normalize the results and avoid words that are too frequent, and thus not useful to\n",
    "characterize the instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a Naïve Bayes classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a Naïve Bayes classifier that is composed of a feature vectorizer\n",
    "and the actual Bayes classifier. We will use the MultinomialNB class from the\n",
    "sklearn.naive_bayes module. \n",
    "\n",
    "In order to compose the classifier with the\n",
    "vectorizer, scikitlearn\n",
    "has a very useful class called Pipeline (available in the sklearn.pipeline\n",
    "module) that eases the construction of a compound classifier, which consists of\n",
    "several vectorizers and classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Evaluate three models with the same Naive Bayes classifier, but with different vectorizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, HashingVectorizer, CountVectorizer\n",
    "\n",
    "clf_1 = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "clf_2 = Pipeline([\n",
    "    ('vect', HashingVectorizer(non_negative=True)),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "clf_3 = Pipeline([\n",
    "    ('vect', TfidfVectorizer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Perform a five-fold cross-validation by using each one of the classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.85782493  0.85725657  0.84664367  0.85911382  0.8458477 ]\n",
      "Mean score: 0.853 (+/-0.003)\n",
      "[ 0.75543767  0.77659857  0.77049615  0.78508888  0.76200584]\n",
      "Mean score: 0.770 (+/-0.005)\n",
      "[ 0.84482759  0.85990979  0.84558238  0.85990979  0.84213319]\n",
      "Mean score: 0.850 (+/-0.004)\n"
     ]
    }
   ],
   "source": [
    "clfs = [clf_1, clf_2, clf_3]\n",
    "for clf in clfs:\n",
    "    evaluate_cross_validation(clf, news.data, news.target, 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CountVectorizer and TfidfVectorizer had similar performances,\n",
    "and much better than HashingVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's continue with TfidfVectorizer; we could try to improve the results by trying\n",
    "to parse the text documents into tokens with a different regular expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default regular expression: ur\"\\b\\w\\w+\\b\" considers alphanumeric characters\n",
    "and the underscore. Perhaps also considering the slash and the dot could improve\n",
    "the tokenization, and begin considering tokens as Wi-Fi and site.com. The new\n",
    "regular expression could be: ur\"\\b[a-z0-9_\\-\\.]+[a-z][a-z0-9_\\-\\.]+\\b\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf_4 = Pipeline([\n",
    "    ('vect', TfidfVectorizer(\n",
    "                token_pattern=r\"\\b[a-z0-9_\\-\\.]+[a-z][a-z0-9_\\-\\.]+\\b\",\n",
    "    )),\n",
    "    ('clf', MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.86100796  0.8718493   0.86203237  0.87291059  0.8588485 ]\n",
      "Mean score: 0.865 (+/-0.003)\n"
     ]
    }
   ],
   "source": [
    "evaluate_cross_validation(clf_4, news.data, news.target, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a slight improvement from 0.86 to 0.87.\n",
    "Another parameter that we can use is stop_words: this argument allows us to pass\n",
    "a list of words we do not want to take into account, such as too frequent words, or\n",
    "words we do not a priori expect to provide information about the particular topic.\n",
    "\n",
    "We will define a function to load the stop words from a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_stop_words():\n",
    "    result = set()\n",
    "    for line in open('stopwords_en.txt', 'r').readlines():\n",
    "        result.add(line.strip())\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop_words = get_stop_words()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a new classifier with this new parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_5 = Pipeline([\n",
    "    ('vect', TfidfVectorizer(\n",
    "                stop_words=stop_words,\n",
    "                token_pattern=r\"\\b[a-z0-9_\\-\\.]+[a-z][a-z0-9_\\-\\.]+\\b\",    \n",
    "    )),\n",
    "    ('clf', MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.88116711  0.89519767  0.88325816  0.89227912  0.88113558]\n",
      "Mean score: 0.887 (+/-0.003)\n"
     ]
    }
   ],
   "source": [
    "evaluate_cross_validation(clf_5, news.data, news.target, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let us look at MultinomialNB parameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to improve by adjusting the alpha parameter on the MultinomialNB classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_7 = Pipeline([\n",
    "    ('vect', TfidfVectorizer(\n",
    "                stop_words=stop_words,\n",
    "                token_pattern=r\"\\b[a-z0-9_\\-\\.]+[a-z][a-z0-9_\\-\\.]+\\b\",         \n",
    "    )),\n",
    "    ('clf', MultinomialNB(alpha=0.01)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.9204244   0.91960732  0.91828071  0.92677103  0.91854603]\n",
      "Mean score: 0.921 (+/-0.002)\n"
     ]
    }
   ],
   "source": [
    "evaluate_cross_validation(clf_7, news.data, news.target, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the performance\n",
    "If we decide that we have made enough improvements in our model, we are ready to\n",
    "evaluate its performance on the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def train_and_evaluate(clf, X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    print (\"Accuracy on training set:\")\n",
    "    print (clf.score(X_train, y_train))\n",
    "    print (\"Accuracy on testing set:\")\n",
    "    print (clf.score(X_test, y_test))\n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    print (\"Classification Report:\")\n",
    "    print (metrics.classification_report(y_test, y_pred))\n",
    "    print (\"Confusion Matrix:\")\n",
    "    print (metrics.confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set:\n",
      "0.996957690675\n",
      "Accuracy on testing set:\n",
      "0.917869269949\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.88      0.91       216\n",
      "          1       0.85      0.85      0.85       246\n",
      "          2       0.91      0.84      0.87       274\n",
      "          3       0.81      0.86      0.83       235\n",
      "          4       0.88      0.90      0.89       231\n",
      "          5       0.89      0.91      0.90       225\n",
      "          6       0.88      0.80      0.84       248\n",
      "          7       0.92      0.93      0.93       275\n",
      "          8       0.96      0.98      0.97       226\n",
      "          9       0.97      0.94      0.96       250\n",
      "         10       0.97      1.00      0.98       257\n",
      "         11       0.97      0.97      0.97       261\n",
      "         12       0.90      0.91      0.91       216\n",
      "         13       0.94      0.95      0.95       257\n",
      "         14       0.94      0.97      0.95       246\n",
      "         15       0.90      0.96      0.93       234\n",
      "         16       0.91      0.97      0.94       218\n",
      "         17       0.97      0.99      0.98       236\n",
      "         18       0.95      0.91      0.93       213\n",
      "         19       0.86      0.78      0.82       148\n",
      "\n",
      "avg / total       0.92      0.92      0.92      4712\n",
      "\n",
      "Confusion Matrix:\n",
      "[[190   0   0   0   1   0   0   0   0   1   0   0   0   1   0   9   2   0\n",
      "    0  12]\n",
      " [  0 208   5   3   3  13   4   0   0   0   0   1   3   2   3   0   0   1\n",
      "    0   0]\n",
      " [  0  11 230  22   1   5   1   0   1   0   0   0   0   0   1   0   1   0\n",
      "    1   0]\n",
      " [  0   6   6 202   9   3   4   0   0   0   0   0   4   0   1   0   0   0\n",
      "    0   0]\n",
      " [  0   2   3   4 208   1   5   0   0   0   2   0   5   0   1   0   0   0\n",
      "    0   0]\n",
      " [  0   9   2   2   1 205   0   1   1   0   0   0   0   2   1   0   0   1\n",
      "    0   0]\n",
      " [  0   2   3  10   6   0 199  14   1   2   0   1   5   2   2   0   0   1\n",
      "    0   0]\n",
      " [  0   1   1   1   1   0   6 257   4   1   0   0   0   1   0   0   2   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   1   1   2 221   0   0   0   0   1   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   1   0   2 236   5   0   1   3   0   1   1   0\n",
      "    0   0]\n",
      " [  0   0   0   1   0   0   0   0   0   0 256   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   1   0   1   0   0   0 254   0   1   0   0   3   0\n",
      "    1   0]\n",
      " [  0   1   0   1   5   1   3   1   0   2   1   1 197   1   2   0   0   0\n",
      "    0   0]\n",
      " [  0   1   0   1   1   0   0   0   0   0   0   2   2 245   3   0   1   0\n",
      "    0   1]\n",
      " [  0   2   0   0   1   0   0   1   0   0   0   0   0   1 238   0   1   0\n",
      "    1   1]\n",
      " [  1   0   1   2   0   0   0   1   0   0   0   1   1   0   1 225   0   1\n",
      "    0   0]\n",
      " [  0   0   1   0   0   0   1   0   1   0   0   1   0   0   0   0 212   0\n",
      "    2   0]\n",
      " [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 234\n",
      "    1   0]\n",
      " [  0   0   0   0   0   0   1   0   0   0   0   2   1   1   0   1   7   3\n",
      "  193   4]\n",
      " [  9   0   0   0   0   1   0   0   0   1   0   0   0   0   0  13   4   1\n",
      "    4 115]]\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate(clf_7, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An accuracy of around 0.91.\n",
    "\n",
    "\n",
    "If we look inside the vectorizer, we can see which tokens have been used to create\n",
    "our dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145767\n"
     ]
    }
   ],
   "source": [
    "print (len(clf_7.named_steps['vect'].get_feature_names()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that the dictionary is composed of 145767 tokens.\n",
    "\n",
    "Let's print the\n",
    "feature names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['...and',\n",
       " '0-.66d8wt',\n",
       " '0-04g55',\n",
       " '0-100mph',\n",
       " '0-13-117441-x--or',\n",
       " '0-3mb',\n",
       " '0-40mb',\n",
       " '0-40volts',\n",
       " '0-5mb',\n",
       " '0-60mph',\n",
       " '0-8.3mb',\n",
       " '0-a00138',\n",
       " '0-byte',\n",
       " '0-defects',\n",
       " '0-e8',\n",
       " '0-for-4',\n",
       " '0-hc',\n",
       " '0-ii',\n",
       " '0-uw',\n",
       " '0-uw0',\n",
       " '0-uw2',\n",
       " '0-uwa',\n",
       " '0-uwt',\n",
       " '0-uwt7',\n",
       " '0-uww',\n",
       " '0-uww7',\n",
       " '0.-w0',\n",
       " '0..x-1',\n",
       " '0.00...nice',\n",
       " '0.02cents',\n",
       " '0.0cb',\n",
       " '0.1-ports',\n",
       " '0.15mb',\n",
       " '0.2d-_',\n",
       " '0.5db',\n",
       " '0.6-micron',\n",
       " '0.65mb',\n",
       " '0.97pl4',\n",
       " '0.b34s_',\n",
       " '0.c0rgo5kj7pp0',\n",
       " '0.c4',\n",
       " '0.jy',\n",
       " '0.s_',\n",
       " '0.tprv6ekj7r',\n",
       " '0.tt',\n",
       " '0.txa_',\n",
       " '0.txc',\n",
       " '0.vpp',\n",
       " '0.vpsll2',\n",
       " '00-index.txt',\n",
       " '000-foot',\n",
       " '000-kg',\n",
       " '000-man',\n",
       " '000-maxwell',\n",
       " '000-strong',\n",
       " '000000.active.spx',\n",
       " '000062david42',\n",
       " '000100255pixel',\n",
       " '0005111312na1em',\n",
       " '0005111312na3em',\n",
       " '000hz',\n",
       " '000iu',\n",
       " '000mg',\n",
       " '000mi',\n",
       " '000miles',\n",
       " '000puq9',\n",
       " '000rpm',\n",
       " '000th',\n",
       " '000ug',\n",
       " '000usd',\n",
       " '0010580b.0b6r49',\n",
       " '0010580b.vma7o9',\n",
       " '0010580b.vmcbrt',\n",
       " '001200201pixel',\n",
       " '002251w.5.734117130',\n",
       " '007bww3',\n",
       " '007gjf3',\n",
       " '00969fba.e640ff10',\n",
       " '0096b0f0.c5de05a0',\n",
       " '0096b11b.08a283a0',\n",
       " '0096b294.aad9c1e0',\n",
       " '00acearl',\n",
       " '00am',\n",
       " '00bjgood',\n",
       " '00cgbabbitt',\n",
       " '00cjmelching',\n",
       " '00cmmiller',\n",
       " '00ecgillespi',\n",
       " '00ecgillespie',\n",
       " '00index',\n",
       " '00lz8bct',\n",
       " '00mbstultz',\n",
       " '00pm',\n",
       " '00pm-9',\n",
       " '00pmlemen',\n",
       " '0100lines',\n",
       " '01050810.vkcsbl',\n",
       " '01050810.vuumdq',\n",
       " '0123456789abcdef',\n",
       " '014t4',\n",
       " '01_introduction.ma',\n",
       " '01apr93.17160985.0059',\n",
       " '01c8',\n",
       " '01f6',\n",
       " '01h0',\n",
       " '01ll',\n",
       " '01ne',\n",
       " '01ob',\n",
       " '01vl2',\n",
       " '01ya',\n",
       " '02-0zl',\n",
       " '02-jul-92',\n",
       " '02-q9ign',\n",
       " '020qw',\n",
       " '026bf',\n",
       " '02_math_model.ma',\n",
       " '02_math_models.ma',\n",
       " '02at',\n",
       " '02bp1m51',\n",
       " '02bz',\n",
       " '02e0',\n",
       " '02f8',\n",
       " '02ixl',\n",
       " '02mm',\n",
       " '02qvq',\n",
       " '02r4e',\n",
       " '02tl',\n",
       " '02tm_',\n",
       " '02tmn',\n",
       " '02va7pu',\n",
       " '02vx',\n",
       " '02vy',\n",
       " '02vyn',\n",
       " '02vz089',\n",
       " '03-sep-1967',\n",
       " '030-based',\n",
       " '0300ff',\n",
       " '03_1_transient_response.ma',\n",
       " '03_2_transient_response.ma',\n",
       " '03_3_transient_response.ma',\n",
       " '03aa',\n",
       " '03ab',\n",
       " '03e8',\n",
       " '03f8',\n",
       " '03ho.lk8',\n",
       " '03hord',\n",
       " '03hz',\n",
       " '03hz.b',\n",
       " '03hz.cj1',\n",
       " '03hz.fg',\n",
       " '03hz.h8o.ci',\n",
       " '03hzri',\n",
       " '03i3',\n",
       " '03ii',\n",
       " '03ii.chzd9',\n",
       " '03imv',\n",
       " '03is',\n",
       " '03j1.lk',\n",
       " '03j1d9',\n",
       " '03k8.chzv',\n",
       " '03k8rg',\n",
       " '03m4u',\n",
       " '03u0',\n",
       " '03vo',\n",
       " '04.cesyy',\n",
       " '0430-1500ut',\n",
       " '0433nl',\n",
       " '044tcya',\n",
       " '045q2',\n",
       " '046p4',\n",
       " '046q2b5u',\n",
       " '046sau',\n",
       " '046um',\n",
       " '04_steady_state_response.ma',\n",
       " '04ax',\n",
       " '04he',\n",
       " '04hj',\n",
       " '04hlal',\n",
       " '04hm34u',\n",
       " '04jdj',\n",
       " '04mk',\n",
       " '04p2',\n",
       " '04trtcp',\n",
       " '04wsedwjy',\n",
       " '04x1',\n",
       " '04zb',\n",
       " '055555556q-34u',\n",
       " '055555556ql34u-34u--jjjjjjj',\n",
       " '05_root_locus.ma',\n",
       " '05apr93.02451203.0049',\n",
       " '05apr93.02678944.0049',\n",
       " '05apr93.13661642.0023',\n",
       " '05bc5cvfq',\n",
       " '05dzu',\n",
       " '05fh',\n",
       " '05gd87g',\n",
       " '05ic',\n",
       " '05jl1i',\n",
       " '05ll',\n",
       " '05lma',\n",
       " '05lxm34',\n",
       " '05lxn',\n",
       " '05pm',\n",
       " '05rov',\n",
       " '05s.5',\n",
       " '0600lines',\n",
       " '06_freq_response.ma',\n",
       " '06a7_e9',\n",
       " '06dz.b',\n",
       " '06eh.c4',\n",
       " '06eh.ya',\n",
       " '06eh.yk6ql2',\n",
       " '06f1',\n",
       " '06hwke',\n",
       " '06ku',\n",
       " '06kv',\n",
       " '06mz',\n",
       " '06n.edo6',\n",
       " '06paul',\n",
       " '06s4bnv',\n",
       " '06tz',\n",
       " '06tzv',\n",
       " '06umv',\n",
       " '06w8',\n",
       " '06zkc4',\n",
       " '07-may-93',\n",
       " '07.sl',\n",
       " '07.v0',\n",
       " '07220yfz',\n",
       " '0776ov_h',\n",
       " '07_state_space.ma',\n",
       " '07aq',\n",
       " '07cgk',\n",
       " '07iz',\n",
       " '07l99',\n",
       " '07lhs',\n",
       " '07qnjbue',\n",
       " '07sc',\n",
       " '07tic',\n",
       " '0824e2vyn',\n",
       " '088z.lk',\n",
       " '08m9.sl',\n",
       " '08oz',\n",
       " '08u12',\n",
       " '08ws',\n",
       " '09_d2p',\n",
       " '09aa',\n",
       " '09g9',\n",
       " '09h3o',\n",
       " '09k_',\n",
       " '09m81h',\n",
       " '09oxdk',\n",
       " '09w0f',\n",
       " '0_8ge',\n",
       " '0_e8',\n",
       " '0_h1',\n",
       " '0_kp82_5',\n",
       " '0_ww',\n",
       " '0_zs',\n",
       " '0a000',\n",
       " '0a1',\n",
       " '0a3',\n",
       " '0a34',\n",
       " '0a4pirs-f0um15',\n",
       " '0a7h23iai7',\n",
       " '0a99',\n",
       " '0ab15j2qf3f',\n",
       " '0adh',\n",
       " '0ae6c',\n",
       " '0ain',\n",
       " '0am',\n",
       " '0amo',\n",
       " '0aujqb',\n",
       " '0av',\n",
       " '0aw',\n",
       " '0ax',\n",
       " '0ayf',\n",
       " '0b-a',\n",
       " '0b-x2',\n",
       " '0b1fatransfer',\n",
       " '0b2',\n",
       " '0b4dam',\n",
       " '0b6er',\n",
       " '0b8',\n",
       " '0b800',\n",
       " '0b800h',\n",
       " '0bh',\n",
       " '0bj',\n",
       " '0bla',\n",
       " '0bm2',\n",
       " '0bn',\n",
       " '0bnw',\n",
       " '0bus',\n",
       " '0bv',\n",
       " '0bvm005',\n",
       " '0bz',\n",
       " '0c000',\n",
       " '0c4v',\n",
       " '0c5r',\n",
       " '0c800',\n",
       " '0cdwkv_',\n",
       " '0cg',\n",
       " '0cgf',\n",
       " '0ct1t',\n",
       " '0cz',\n",
       " '0d-jm',\n",
       " '0d.8',\n",
       " '0d.x',\n",
       " '0d1',\n",
       " '0d2',\n",
       " '0d36b',\n",
       " '0d4',\n",
       " '0d6',\n",
       " '0d7',\n",
       " '0d84.sz',\n",
       " '0db',\n",
       " '0ded',\n",
       " '0df',\n",
       " '0dfsx',\n",
       " '0dfvij',\n",
       " '0dfyl',\n",
       " '0dgq',\n",
       " '0dgw83',\n",
       " '0dh',\n",
       " '0di',\n",
       " '0dj',\n",
       " '0dl',\n",
       " '0dn1',\n",
       " '0dnynno-7',\n",
       " '0doh7',\n",
       " '0du',\n",
       " '0dum',\n",
       " '0dvf2l',\n",
       " '0dy.tm',\n",
       " '0e000',\n",
       " '0e1',\n",
       " '0e3udg11',\n",
       " '0e4',\n",
       " '0e75',\n",
       " '0e75x',\n",
       " '0e9',\n",
       " '0e97pm4',\n",
       " '0e97pm8',\n",
       " '0e97pms8',\n",
       " '0echy',\n",
       " '0ek',\n",
       " '0ek-c8v',\n",
       " '0ek-c8v-c8v-c8v-c9n',\n",
       " '0ek-c9n',\n",
       " '0ek-c9nv1',\n",
       " '0ekr',\n",
       " '0en36',\n",
       " '0ep',\n",
       " '0erdivbud',\n",
       " '0ex',\n",
       " '0ex6',\n",
       " '0ez',\n",
       " '0f.1p',\n",
       " '0f000',\n",
       " '0f0064',\n",
       " '0f1',\n",
       " '0f18fa5b225d03d3a401973b4318dd0e',\n",
       " '0f1u',\n",
       " '0f3',\n",
       " '0f8',\n",
       " '0ffnm',\n",
       " '0fgj5',\n",
       " '0fh',\n",
       " '0fhmt',\n",
       " '0fj',\n",
       " '0fo0',\n",
       " '0forqfa00iuzmatnmz',\n",
       " '0fovj7i00wb4miumht',\n",
       " '0fpzy',\n",
       " '0fq',\n",
       " '0frolv200awvi3iv4s',\n",
       " '0fs',\n",
       " '0fv8',\n",
       " '0fw',\n",
       " '0fz1mtpe',\n",
       " '0g12o',\n",
       " '0g19',\n",
       " '0g4',\n",
       " '0g8',\n",
       " '0g_g',\n",
       " '0gg',\n",
       " '0ggu',\n",
       " '0ggv',\n",
       " '0gi',\n",
       " '0gij',\n",
       " '0giyx',\n",
       " '0gj',\n",
       " '0gl',\n",
       " '0gyts',\n",
       " '0gz',\n",
       " '0h-0',\n",
       " '0h-p',\n",
       " '0h0',\n",
       " '0h2',\n",
       " '0h23tc',\n",
       " '0h4ou',\n",
       " '0h6o481w8h1t2',\n",
       " '0h6xl',\n",
       " '0h8',\n",
       " '0h9',\n",
       " '0h9_',\n",
       " '0ha',\n",
       " '0ha7b0',\n",
       " '0hb',\n",
       " '0hd',\n",
       " '0hdf',\n",
       " '0hg',\n",
       " '0hg8erx',\n",
       " '0hgw',\n",
       " '0hh9',\n",
       " '0hjt',\n",
       " '0hm',\n",
       " '0hpg5x-t',\n",
       " '0hq',\n",
       " '0hq4',\n",
       " '0ht',\n",
       " '0hyx',\n",
       " '0i-5u',\n",
       " '0i.3',\n",
       " '0i.bn',\n",
       " '0i0_',\n",
       " '0i281',\n",
       " '0i3rq',\n",
       " '0i7cx',\n",
       " '0i91n',\n",
       " '0ic',\n",
       " '0ieo2el',\n",
       " '0ih',\n",
       " '0ij',\n",
       " '0is0',\n",
       " '0iv',\n",
       " '0ivbg6',\n",
       " '0ivbtm9',\n",
       " '0ivbud',\n",
       " '0ivbud9',\n",
       " '0ivbudk',\n",
       " '0ivbvl',\n",
       " '0ivc',\n",
       " '0ive',\n",
       " '0ive8',\n",
       " '0ivf1dk',\n",
       " '0ivf2l',\n",
       " '0ivmhm',\n",
       " '0ivmhm9',\n",
       " '0ivmiu',\n",
       " '0ivmk',\n",
       " '0iwx.c',\n",
       " '0iwx.c0rvl',\n",
       " '0j4',\n",
       " '0j5',\n",
       " '0j5-57',\n",
       " '0j_0-3',\n",
       " '0ja3d',\n",
       " '0jb6pwzasj',\n",
       " '0je',\n",
       " '0jeiq',\n",
       " '0jf',\n",
       " '0jh',\n",
       " '0jkh',\n",
       " '0jr',\n",
       " '0jt1',\n",
       " '0jx',\n",
       " '0jx5gvp',\n",
       " '0jy',\n",
       " '0jz',\n",
       " '0k-2u',\n",
       " '0k5',\n",
       " '0k82',\n",
       " '0k83a',\n",
       " '0k9jsu',\n",
       " '0kbfkp',\n",
       " '0kd',\n",
       " '0kh',\n",
       " '0khp',\n",
       " '0kj',\n",
       " '0km',\n",
       " '0km2',\n",
       " '0kqi',\n",
       " '0kr',\n",
       " '0ks',\n",
       " '0ksx',\n",
       " '0kt',\n",
       " '0kwbw',\n",
       " '0l0',\n",
       " '0l5h06j',\n",
       " '0l5h06l',\n",
       " '0l7',\n",
       " '0la1z',\n",
       " '0lc',\n",
       " '0lhf',\n",
       " '0li',\n",
       " '0ll',\n",
       " '0lme3vkdw6wo',\n",
       " '0lnbq',\n",
       " '0lnnm',\n",
       " '0lo',\n",
       " '0lowt',\n",
       " '0lq',\n",
       " '0ls8',\n",
       " '0lsbd',\n",
       " '0lu',\n",
       " '0lv',\n",
       " '0lv1a4e3',\n",
       " '0lzi3-z-5pzk8',\n",
       " '0m0x',\n",
       " '0m1qz',\n",
       " '0m2',\n",
       " '0m5',\n",
       " '0m6bq',\n",
       " '0m75',\n",
       " '0m75de06b4q',\n",
       " '0m75u',\n",
       " '0m75u9',\n",
       " '0m8',\n",
       " '0m8b',\n",
       " '0m8bnh',\n",
       " '0m8w',\n",
       " '0ma',\n",
       " '0max',\n",
       " '0mbz',\n",
       " '0mc',\n",
       " '0megyt',\n",
       " '0mez-k9k',\n",
       " '0mf',\n",
       " '0mi',\n",
       " '0mis',\n",
       " '0mjx9',\n",
       " '0mk',\n",
       " '0mk.sl',\n",
       " '0mk80',\n",
       " '0mkg',\n",
       " '0ml',\n",
       " '0mm2',\n",
       " '0moa',\n",
       " '0mph',\n",
       " '0mq69',\n",
       " '0ms0',\n",
       " '0msd',\n",
       " '0mvbdi',\n",
       " '0mvbf',\n",
       " '0mvbgt',\n",
       " '0mvbtmvo2',\n",
       " '0mvh',\n",
       " '0mvmk',\n",
       " '0mxb',\n",
       " '0n1',\n",
       " '0n3',\n",
       " '0n5',\n",
       " '0nb',\n",
       " '0ne1',\n",
       " '0neat',\n",
       " '0nf',\n",
       " '0nfdh',\n",
       " '0nh',\n",
       " '0ni4',\n",
       " '0niy',\n",
       " '0nq',\n",
       " '0nt',\n",
       " '0ntmrn',\n",
       " '0ntv.273g',\n",
       " '0o-y',\n",
       " '0o2',\n",
       " '0o2d',\n",
       " '0o3',\n",
       " '0o6kgm',\n",
       " '0o_2',\n",
       " '0oa',\n",
       " '0ods2b8',\n",
       " '0of',\n",
       " '0oft',\n",
       " '0ogl',\n",
       " '0oi',\n",
       " '0ol',\n",
       " '0ol63',\n",
       " '0olmi2',\n",
       " '0omdcua8a4',\n",
       " '0opco-dw',\n",
       " '0oqis',\n",
       " '0os8is7u',\n",
       " '0otv',\n",
       " '0otz',\n",
       " '0p0',\n",
       " '0p1i5',\n",
       " '0p38',\n",
       " '0p4u-34u',\n",
       " '0p5f',\n",
       " '0p6',\n",
       " '0p6a3b1w165w',\n",
       " '0p7',\n",
       " '0p8',\n",
       " '0p8jiac',\n",
       " '0p9c',\n",
       " '0p_7924x',\n",
       " '0pd',\n",
       " '0pe0',\n",
       " '0pfbd',\n",
       " '0pj',\n",
       " '0pl4',\n",
       " '0pn',\n",
       " '0pp',\n",
       " '0prum0q',\n",
       " '0ptm',\n",
       " '0pto',\n",
       " '0pvhr4',\n",
       " '0pvx',\n",
       " '0px8r',\n",
       " '0pxf1l',\n",
       " '0pxve0b',\n",
       " '0pzwx',\n",
       " '0q-_0',\n",
       " '0q.-xny5gx',\n",
       " '0q.x1',\n",
       " '0q1t',\n",
       " '0q76t',\n",
       " '0qas',\n",
       " '0qax',\n",
       " '0qb',\n",
       " '0qhh',\n",
       " '0qljfw',\n",
       " '0qm0n0',\n",
       " '0qq',\n",
       " '0qqiyay6s',\n",
       " '0qu',\n",
       " '0quh',\n",
       " '0qur',\n",
       " '0qv',\n",
       " '0qvn',\n",
       " '0qvq',\n",
       " '0qvql6s3b',\n",
       " '0qvqma',\n",
       " '0qvqn',\n",
       " '0qvqn1',\n",
       " '0qw',\n",
       " '0qwa',\n",
       " '0qwol6s3',\n",
       " '0qwomk4',\n",
       " '0qxp',\n",
       " '0r.da',\n",
       " '0r1l40',\n",
       " '0r2',\n",
       " '0r445',\n",
       " '0r66',\n",
       " '0r_',\n",
       " '0razbbh107h',\n",
       " '0rchzv',\n",
       " '0rdf',\n",
       " '0rfumrd',\n",
       " '0rgt9',\n",
       " '0rhj',\n",
       " '0rht',\n",
       " '0rk',\n",
       " '0rn',\n",
       " '0rr',\n",
       " '0rtr-58',\n",
       " '0ru',\n",
       " '0rv',\n",
       " '0ry48x',\n",
       " '0s03',\n",
       " '0s1',\n",
       " '0s2',\n",
       " '0s4',\n",
       " '0s792j8jdn',\n",
       " '0s9',\n",
       " '0sc3',\n",
       " '0scr',\n",
       " '0sk',\n",
       " '0sl',\n",
       " '0sla0t',\n",
       " '0slrmc',\n",
       " '0smpax',\n",
       " '0std',\n",
       " '0sx',\n",
       " '0sz',\n",
       " '0sz5u',\n",
       " '0sz6_f',\n",
       " '0t-l',\n",
       " '0t-w',\n",
       " '0t-wb',\n",
       " '0t-wi_6ukx',\n",
       " '0t-wj',\n",
       " '0t-wm',\n",
       " '0t-wmxg',\n",
       " '0t-wmz',\n",
       " '0t.u',\n",
       " '0t2o',\n",
       " '0t7-u',\n",
       " '0t7s',\n",
       " '0tb',\n",
       " '0tbxn',\n",
       " '0tbxom',\n",
       " '0tbxom4',\n",
       " '0tbxom4u-3l',\n",
       " '0tfj',\n",
       " '0tg',\n",
       " '0tgx',\n",
       " '0tgx8',\n",
       " '0th',\n",
       " '0thbq',\n",
       " '0tig1',\n",
       " '0tk',\n",
       " '0tmobi',\n",
       " '0tn',\n",
       " '0tp',\n",
       " '0tq',\n",
       " '0tq33',\n",
       " '0tq6',\n",
       " '0trb',\n",
       " '0tsi',\n",
       " '0tsq3',\n",
       " '0tu525vk',\n",
       " '0tv_g',\n",
       " '0tzv',\n",
       " '0u-1y',\n",
       " '0u1',\n",
       " '0u14',\n",
       " '0u140w',\n",
       " '0u2',\n",
       " '0u48c',\n",
       " '0u59',\n",
       " '0ud',\n",
       " '0ue',\n",
       " '0ulx',\n",
       " '0un',\n",
       " '0up9',\n",
       " '0urx',\n",
       " '0uuv',\n",
       " '0uv',\n",
       " '0uxgblk',\n",
       " '0uy',\n",
       " '0v.zlp',\n",
       " '0v2',\n",
       " '0v34b',\n",
       " '0v6p',\n",
       " '0va',\n",
       " '0vah',\n",
       " '0vah8',\n",
       " '0vb.y',\n",
       " '0vbs',\n",
       " '0vcol6s3',\n",
       " '0vcol6s3m',\n",
       " '0vd',\n",
       " '0vet',\n",
       " '0vg',\n",
       " '0vg09_',\n",
       " '0vkjsj1',\n",
       " '0vkjzl',\n",
       " '0vkzyrah8',\n",
       " '0vow8',\n",
       " '0vpy8cl',\n",
       " '0vuimj',\n",
       " '0vv6',\n",
       " '0vx48',\n",
       " '0vy4b',\n",
       " '0w-p',\n",
       " '0w0',\n",
       " '0w013',\n",
       " '0w25z0r8p',\n",
       " '0w2z2b1w164w',\n",
       " '0w3',\n",
       " '0w4',\n",
       " '0w5',\n",
       " '0w5r',\n",
       " '0w8',\n",
       " '0w9_',\n",
       " '0wa',\n",
       " '0wa8nfu',\n",
       " '0wax0t',\n",
       " '0wc',\n",
       " '0we',\n",
       " '0wiz',\n",
       " '0wj',\n",
       " '0wk',\n",
       " '0wk.lhz.d',\n",
       " '0wkg',\n",
       " '0wkz',\n",
       " '0wmfhhm',\n",
       " '0ws',\n",
       " '0wu',\n",
       " '0wv',\n",
       " '0ww',\n",
       " '0wxb',\n",
       " '0wzu',\n",
       " '0x.xn',\n",
       " '0x0',\n",
       " '0x00',\n",
       " '0x00-0x1f',\n",
       " '0x000c',\n",
       " '0x000f',\n",
       " '0x0069',\n",
       " '0x01',\n",
       " '0x02',\n",
       " '0x03',\n",
       " '0x03f8',\n",
       " '0x04',\n",
       " '0x08',\n",
       " '0x0f',\n",
       " '0x10',\n",
       " '0x100',\n",
       " '0x14',\n",
       " '0x170',\n",
       " '0x2',\n",
       " '0x20',\n",
       " '0x200',\n",
       " '0x201',\n",
       " '0x21',\n",
       " '0x22',\n",
       " '0x23',\n",
       " '0x24',\n",
       " '0x25',\n",
       " '0x27',\n",
       " '0x280',\n",
       " '0x29',\n",
       " '0x2e0',\n",
       " '0x2e8',\n",
       " '0x30',\n",
       " '0x360-0x37f',\n",
       " '0x37a',\n",
       " '0x37f',\n",
       " '0x38',\n",
       " '0x3c',\n",
       " '0x3d4',\n",
       " '0x3f',\n",
       " '0x40',\n",
       " '0x4000',\n",
       " '0x400000',\n",
       " '0x4d42',\n",
       " '0x500043',\n",
       " '0x5i',\n",
       " '0x6',\n",
       " '0x60',\n",
       " '0x62',\n",
       " '0x6b',\n",
       " '0x6kj4m',\n",
       " '0x7',\n",
       " '0x7f',\n",
       " '0x80',\n",
       " '0x800000',\n",
       " '0x80079',\n",
       " '0x8007a',\n",
       " '0x8007b',\n",
       " '0x80080',\n",
       " '0x80083',\n",
       " '0x9ma1f6',\n",
       " '0x9o01f6',\n",
       " '0xa',\n",
       " '0xa00000',\n",
       " '0xa3',\n",
       " '0xa7',\n",
       " '0xa8',\n",
       " '0xb',\n",
       " '0xb00003',\n",
       " '0xbum1',\n",
       " '0xc0',\n",
       " '0xc010',\n",
       " '0xc018',\n",
       " '0xd',\n",
       " '0xd000',\n",
       " '0xd0000d',\n",
       " '0xd0001d',\n",
       " '0xe0000d',\n",
       " '0xff',\n",
       " '0xff00',\n",
       " '0xff0000',\n",
       " '0xffffffff',\n",
       " '0xh',\n",
       " '0xhb',\n",
       " '0xhi',\n",
       " '0xi',\n",
       " '0xw',\n",
       " '0xx',\n",
       " '0y.3dy',\n",
       " '0y3',\n",
       " '0y4',\n",
       " '0yf07nq94',\n",
       " '0yg',\n",
       " '0yh_0lxiad',\n",
       " '0yhk',\n",
       " '0yi0v',\n",
       " '0yj',\n",
       " '0yldm',\n",
       " '0ytj',\n",
       " '0yu85',\n",
       " '0yxey',\n",
       " '0yxt',\n",
       " '0z-1l',\n",
       " '0z.xf',\n",
       " '0z00.iim0',\n",
       " '0z4',\n",
       " '0z4dw_lqxk',\n",
       " '0z7w_',\n",
       " '0z8',\n",
       " '0zd',\n",
       " '0zphu',\n",
       " '0zsq9',\n",
       " '0zsqk',\n",
       " '0zv',\n",
       " '0zx',\n",
       " '0zy',\n",
       " '0zz',\n",
       " '0zz8b',\n",
       " '0zznm',\n",
       " '0zzum',\n",
       " '0zzum1',\n",
       " '1--q9ux',\n",
       " '1-.jhhgczw',\n",
       " '1-0-att-0-700-wmurray',\n",
       " '1-15amp',\n",
       " '1-1p0b4p2',\n",
       " '1-2mb',\n",
       " '1-35io',\n",
       " '1-38.ay.nk',\n",
       " '1-3ghz',\n",
       " '1-3kbyte',\n",
       " '1-408-730-5750....sam',\n",
       " '1-408-736-2000...fax',\n",
       " '1-5w22ya9',\n",
       " '1-6eiqy',\n",
       " '1-7sl',\n",
       " '1-800-245-unix',\n",
       " '1-800-3-ibm-os2',\n",
       " '1-800-388-plus',\n",
       " '1-800-3cl-aris',\n",
       " '1-800-4-cancer',\n",
       " '1-800-441-math',\n",
       " '1-800-828-unix',\n",
       " '1-800-832-4778.....sam',\n",
       " '1-800-886-lyme',\n",
       " '1-800-8applix',\n",
       " '1-800-ama-join',\n",
       " '1-800-clu-bmac',\n",
       " '1-800-dataset',\n",
       " '1-800-digital',\n",
       " '1-800-efa-1000',\n",
       " '1-800-hpclass',\n",
       " '1-800-mac-stuf',\n",
       " '1-800-mac-usa1',\n",
       " '1-800-sos-apple',\n",
       " '1-800-trainer',\n",
       " '1-800-uwh-iner',\n",
       " '1-900-got-srcs',\n",
       " '1-900-quoteme',\n",
       " '1-apr-92',\n",
       " '1-b-1',\n",
       " '1-bit',\n",
       " '1-bit-per-pixel',\n",
       " '1-canucks',\n",
       " '1-day',\n",
       " '1-etha0',\n",
       " '1-foot',\n",
       " '1-for-1',\n",
       " '1-in-3',\n",
       " '1-inch',\n",
       " '1-kh',\n",
       " '1-line',\n",
       " '1-mar-93',\n",
       " '1-meg',\n",
       " '1-mile',\n",
       " '1-millisecond',\n",
       " '1-pc',\n",
       " '1-penguins',\n",
       " '1-qn2j2l8',\n",
       " '1-run',\n",
       " '1-screen',\n",
       " '1-slight',\n",
       " '1-to-1',\n",
       " '1-u9',\n",
       " '1-xpi',\n",
       " '1-y2',\n",
       " '1-year',\n",
       " '1.054589e-34',\n",
       " '1.0b14',\n",
       " '1.0b15',\n",
       " '1.0b16',\n",
       " '1.16mg',\n",
       " '1.1scd1',\n",
       " '1.20in-reply-to',\n",
       " '1.24in-reply-to',\n",
       " '1.25mb',\n",
       " '1.2f33enh',\n",
       " '1.2gb',\n",
       " '1.2mb',\n",
       " '1.2meg',\n",
       " '1.327e20',\n",
       " '1.33mb',\n",
       " '1.3807e-23',\n",
       " '1.3ci',\n",
       " '1.3mb',\n",
       " '1.4-b1',\n",
       " '1.41.uac',\n",
       " '1.42e-4',\n",
       " '1.44mb',\n",
       " '1.44meg',\n",
       " '1.44mg',\n",
       " '1.496e11',\n",
       " '1.4e-23',\n",
       " ...]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_7.named_steps['vect'].get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
